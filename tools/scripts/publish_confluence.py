#!/usr/bin/env python3
"""
Confluence Server/DC ìë™ ê²Œì‹œ ìŠ¤í¬ë¦½íŠ¸.

docs/*.md ë¬¸ì„œì™€ state/ ì§„ë‹¨ ê²°ê³¼ JSONì„ Confluenceì— ìë™ ê²Œì‹œí•œë‹¤.
í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë§Œ ì‚¬ìš©í•˜ë©°, markdown íŒ¨í‚¤ì§€ëŠ” ì„ íƒì (optional)ì´ë‹¤.

Usage:
    python tools/scripts/publish_confluence.py --dry-run
    python tools/scripts/publish_confluence.py
    python tools/scripts/publish_confluence.py --filter docs/00_overview.md
    python tools/scripts/publish_confluence.py --map tools/confluence_page_map.json
"""
import argparse
import base64
import json
import os
import re
import sys
import urllib.error
import urllib.parse
import urllib.request
from html import escape as html_escape

# ---------------------------------------------------------------------------
# .env loader
# ---------------------------------------------------------------------------

def load_env(path=".env"):
    """Parse a .env file (KEY=VALUE lines) into os.environ."""
    if not os.path.isfile(path):
        return
    with open(path, encoding="utf-8") as fh:
        for line in fh:
            line = line.strip()
            if not line or line.startswith("#"):
                continue
            if "=" not in line:
                continue
            key, _, value = line.partition("=")
            key = key.strip()
            value = value.strip()
            # strip surrounding quotes
            if len(value) >= 2 and value[0] == value[-1] and value[0] in ('"', "'"):
                value = value[1:-1]
            os.environ.setdefault(key, value)

# ---------------------------------------------------------------------------
# Configuration
# ---------------------------------------------------------------------------

def get_config():
    """Load configuration from environment variables and validate."""
    cfg = {
        "base_url": os.environ.get("CONFLUENCE_BASE_URL", "").rstrip("/"),
        "space_key": os.environ.get("CONFLUENCE_SPACE_KEY", ""),
        "parent_id": os.environ.get("CONFLUENCE_PARENT_ID", ""),
        "user": os.environ.get("CONFLUENCE_USER", ""),
        "token": os.environ.get("CONFLUENCE_TOKEN", ""),
    }
    missing = [k for k in ("base_url", "space_key", "parent_id", "token") if not cfg[k]]
    if missing:
        print(f"[ERROR] Missing required environment variables: "
              f"{', '.join('CONFLUENCE_' + k.upper() for k in missing)}", file=sys.stderr)
        print("       Copy .env.example to .env and fill in the values.", file=sys.stderr)
        sys.exit(1)
    return cfg

# ---------------------------------------------------------------------------
# Auth
# ---------------------------------------------------------------------------

def build_auth_header(cfg):
    """Return Authorization header dict.

    If CONFLUENCE_USER is set  -> Basic base64(user:token)
    Otherwise                  -> Bearer token (PAT)
    """
    if cfg["user"]:
        cred = base64.b64encode(f"{cfg['user']}:{cfg['token']}".encode()).decode()
        return {"Authorization": f"Basic {cred}"}
    return {"Authorization": f"Bearer {cfg['token']}"}

# ---------------------------------------------------------------------------
# HTTP helper
# ---------------------------------------------------------------------------

def confluence_api(cfg, method, path, body=None):
    """urllib-based HTTP wrapper for Confluence REST API.

    Returns parsed JSON response or None for 204/empty bodies.
    Raises SystemExit on HTTP errors.
    """
    url = f"{cfg['base_url']}{path}"
    headers = {
        "Content-Type": "application/json; charset=utf-8",
        "Accept": "application/json",
    }
    headers.update(build_auth_header(cfg))

    data = json.dumps(body).encode("utf-8") if body else None
    req = urllib.request.Request(url, data=data, headers=headers, method=method)

    try:
        with urllib.request.urlopen(req) as resp:
            raw = resp.read()
            if not raw:
                return None
            return json.loads(raw)
    except urllib.error.HTTPError as exc:
        err_body = exc.read().decode("utf-8", errors="replace")
        print(f"[ERROR] {method} {url} -> {exc.code}", file=sys.stderr)
        print(f"        {err_body[:500]}", file=sys.stderr)
        raise SystemExit(1) from exc
    except urllib.error.URLError as exc:
        print(f"[ERROR] Cannot reach {url}: {exc.reason}", file=sys.stderr)
        raise SystemExit(1) from exc

# ---------------------------------------------------------------------------
# Confluence CRUD
# ---------------------------------------------------------------------------

def find_page_by_title(cfg, title):
    """Search for an existing page by exact title in the configured space.

    Returns {"id": ..., "version": {"number": N}} or None.
    """
    params = urllib.parse.urlencode({
        "title": title,
        "spaceKey": cfg["space_key"],
        "expand": "version",
    })
    result = confluence_api(cfg, "GET", f"/rest/api/content?{params}")
    if result and result.get("results"):
        page = result["results"][0]
        return {"id": page["id"], "version": page["version"]["number"]}
    return None


def create_page(cfg, title, body_xhtml, parent_id):
    """Create a new Confluence page under *parent_id*."""
    payload = {
        "type": "page",
        "title": title,
        "space": {"key": cfg["space_key"]},
        "ancestors": [{"id": str(parent_id)}],
        "body": {
            "storage": {
                "value": body_xhtml,
                "representation": "storage",
            }
        },
    }
    result = confluence_api(cfg, "POST", "/rest/api/content", payload)
    return result["id"]


def update_page(cfg, page_id, title, body_xhtml, version, parent_id=None):
    """Update an existing Confluence page (version + 1).

    If *parent_id* is given the page is moved under that parent.
    """
    payload = {
        "type": "page",
        "title": title,
        "version": {"number": version + 1},
        "body": {
            "storage": {
                "value": body_xhtml,
                "representation": "storage",
            }
        },
    }
    if parent_id is not None:
        payload["ancestors"] = [{"id": str(parent_id)}]
    confluence_api(cfg, "PUT", f"/rest/api/content/{page_id}", payload)
    return page_id


def publish_page(cfg, title, body_xhtml, parent_id):
    """Idempotent publish: create if new, update (and move) if exists."""
    existing = find_page_by_title(cfg, title)
    if existing:
        update_page(cfg, existing["id"], title, body_xhtml,
                    existing["version"], parent_id=parent_id)
        return existing["id"], "updated"
    page_id = create_page(cfg, title, body_xhtml, parent_id)
    return page_id, "created"

# ---------------------------------------------------------------------------
# Markdown -> XHTML
# ---------------------------------------------------------------------------

def _md_to_xhtml_lib(md_text):
    """Convert Markdown to XHTML using the markdown package."""
    import markdown  # noqa: F811
    return markdown.markdown(
        md_text,
        extensions=["tables", "fenced_code"],
        output_format="xhtml",
    )


def _md_to_xhtml_fallback(md_text):
    """Regex-based Markdown to XHTML fallback (no external deps)."""
    lines = md_text.split("\n")
    html_parts = []
    in_code_block = False
    code_lang = ""
    code_lines = []
    table_rows = []

    def flush_table():
        if not table_rows:
            return ""
        out = ['<table><tbody>']
        for i, row in enumerate(table_rows):
            tag = "th" if i == 0 else "td"
            cells = [c.strip() for c in row.split("|")]
            cells = [c for c in cells if c]
            out.append("<tr>" + "".join(f"<{tag}>{html_escape(c)}</{tag}>" for c in cells) + "</tr>")
        out.append("</tbody></table>")
        table_rows.clear()
        return "\n".join(out)

    for line in lines:
        # Confluence anchor token: [[ANCHOR:name]]
        if line.startswith("[[ANCHOR:") and line.endswith("]]"):
            name = line[len("[[ANCHOR:"):-2]
            name = html_escape(name)
            html_parts.append(
                f'<ac:structured-macro ac:name="anchor">'
                f'<ac:parameter ac:name="name">{name}</ac:parameter>'
                f'</ac:structured-macro>'
            )
            continue
        # fenced code block
        m_fence = re.match(r'^```(\w*)$', line)
        if m_fence:
            if in_code_block:
                html_parts.append(_code_macro("\n".join(code_lines), code_lang))
                code_lines = []
                in_code_block = False
            else:
                html_parts.append(flush_table())
                in_code_block = True
                code_lang = m_fence.group(1) or "text"
            continue
        if in_code_block:
            code_lines.append(line)
            continue

        # table row
        if "|" in line:
            stripped = line.strip()
            if re.match(r'^[\|\s\-:]+$', stripped):
                continue  # separator row
            table_rows.append(stripped)
            continue
        else:
            html_parts.append(flush_table())

        # headings
        m_h = re.match(r'^(#{1,6})\s+(.*)', line)
        if m_h:
            level = len(m_h.group(1))
            text = m_h.group(2)
            html_parts.append(f"<h{level}>{html_escape(text)}</h{level}>")
            continue

        # blank line
        if not line.strip():
            html_parts.append("")
            continue

        # inline formatting then wrap in <p>
        text = html_escape(line)
        text = re.sub(r'\*\*(.+?)\*\*', r'<strong>\1</strong>', text)
        text = re.sub(r'\*(.+?)\*', r'<em>\1</em>', text)
        text = re.sub(r'`(.+?)`', r'<code>\1</code>', text)
        html_parts.append(f"<p>{text}</p>")

    html_parts.append(flush_table())
    return "\n".join(html_parts)


def md_to_xhtml(md_text):
    """Convert Markdown text to XHTML, preferring the markdown package."""
    def _preprocess_anchors(text: str) -> str:
        # Convert <a id="name"></a> to token so both paths can render to Confluence anchor macro.
        def repl(match):
            name = match.group(1)
            return f"[[ANCHOR:{name}]]"
        return re.sub(r'<a\\s+id=["\\\']([^"\\\']+)["\\\']\\s*></a>', repl, text)

    def _postprocess_anchors(xhtml: str) -> str:
        def repl(match):
            name = html_escape(match.group(1))
            return (
                f'<ac:structured-macro ac:name="anchor">'
                f'<ac:parameter ac:name="name">{name}</ac:parameter>'
                f'</ac:structured-macro>'
            )
        return re.sub(r'\[\[ANCHOR:([^\]]+)\]\]', repl, xhtml)

    md_text = _preprocess_anchors(md_text)
    try:
        return _postprocess_anchors(_md_to_xhtml_lib(md_text))
    except ImportError:
        return _postprocess_anchors(_md_to_xhtml_fallback(md_text))

# ---------------------------------------------------------------------------
# JSON -> XHTML helpers
# ---------------------------------------------------------------------------

def _code_macro(code_text, lang="text"):
    """Wrap code in Confluence code macro (Storage Format)."""
    return (
        f'<ac:structured-macro ac:name="code">'
        f'<ac:parameter ac:name="language">{html_escape(lang)}</ac:parameter>'
        f'<ac:plain-text-body><![CDATA[{code_text}]]></ac:plain-text-body>'
        f'</ac:structured-macro>'
    )


def _severity_badge(severity):
    """Return Confluence status macro for severity level."""
    color_map = {
        "Critical": "Red",
        "High": "Red",
        "Medium": "Yellow",
        "Low": "Blue",
        "Info": "Grey",
    }
    color = color_map.get(severity, "Grey")
    return (
        f'<ac:structured-macro ac:name="status">'
        f'<ac:parameter ac:name="colour">{color}</ac:parameter>'
        f'<ac:parameter ac:name="title">{html_escape(severity)}</ac:parameter>'
        f'</ac:structured-macro>'
    )


def _table(headers, rows):
    """Build an XHTML table from headers and rows."""
    parts = ["<table><thead><tr>"]
    for h in headers:
        parts.append(f"<th>{h}</th>")
    parts.append("</tr></thead><tbody>")
    for row in rows:
        parts.append("<tr>")
        for cell in row:
            parts.append(f"<td>{cell}</td>")
        parts.append("</tr>")
    parts.append("</tbody></table>")
    return "".join(parts)

# ---------------------------------------------------------------------------
# JSON -> XHTML by type
# ---------------------------------------------------------------------------

def _json_to_xhtml_asset(data):
    """Convert task_11 (asset identification) JSON to XHTML."""
    parts = [f"<h2>ìì‚° ì‹ë³„ ê²°ê³¼ (Task {html_escape(str(data.get('task_id', '')))})</h2>"]

    findings = data.get("findings", [])
    if findings:
        headers = ["ì„œë¹„ìŠ¤ ê·¸ë£¹", "ìì‚°ëª…", "í™˜ê²½", "ë„ë©”ì¸", "ê¸°ìˆ  ìŠ¤íƒ", "ìš©ë„", "ë…¸ì¶œ", "ì¸ì¦"]
        rows = []
        for f in findings:
            tech = ", ".join(f.get("tech_stack", [])) if isinstance(f.get("tech_stack"), list) else ""
            rows.append([
                html_escape(str(f.get("service_group", ""))),
                html_escape(str(f.get("asset_name", ""))),
                html_escape(str(f.get("environment", ""))),
                html_escape(str(f.get("domain", ""))),
                html_escape(tech),
                html_escape(str(f.get("purpose", ""))),
                html_escape(str(f.get("exposure", ""))),
                html_escape(str(f.get("has_auth", ""))),
            ])
        parts.append(_table(headers, rows))

    # detailed info for first asset (with full tech details)
    for f in findings:
        if f.get("security_components"):
            parts.append(f"<h3>ë³´ì•ˆ ì»´í¬ë„ŒíŠ¸ ({html_escape(str(f.get('asset_name', '')))} - {html_escape(str(f.get('environment', '')))})</h3>")
            parts.append("<ul>")
            for comp in f["security_components"]:
                parts.append(f"<li>{html_escape(comp)}</li>")
            parts.append("</ul>")
        if f.get("external_services"):
            parts.append(f"<h3>ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ë™</h3>")
            parts.append("<ul>")
            for svc in f["external_services"]:
                parts.append(f"<li>{html_escape(svc)}</li>")
            parts.append("</ul>")

    meta = data.get("metadata", {})
    if meta:
        parts.append("<h3>ë©”íƒ€ë°ì´í„°</h3>")
        parts.append(f"<p>ì¶œì²˜: {html_escape(str(meta.get('source_file', '')))}</p>")
        parts.append(f"<p>ì „ì²´ ìì‚° ìˆ˜: {meta.get('total_assets', 0)}</p>")

    return "\n".join(parts)


def _json_to_xhtml_api(data):
    """Convert API inventory JSON to XHTML.

    Supports both:
    - task_21 standard format (findings key)
    - scan_api.py v3.0 format (endpoints key + auth_stats + resolved_fields)
    """
    # --- scan_api.py v3.0 format (endpoints key) ---
    if "endpoints" in data:
        return _json_to_xhtml_api_inventory(data)

    # --- task_21 standard format (findings key) ---
    task_id = html_escape(str(data.get("task_id", "")))
    target = html_escape(str(data.get("target", "")))
    parts = [f"<h2>API ì¸ë²¤í† ë¦¬ (Task {task_id})</h2>"]
    if target:
        parts.append(f"<p><strong>ëŒ€ìƒ:</strong> {target}</p>")

    # scan scope
    scope = data.get("scan_scope", {})
    if scope:
        parts.append("<h3>ìŠ¤ìº” ë²”ìœ„</h3>")
        sc_headers = ["í•­ëª©", "ê°’"]
        sc_rows = []
        if scope.get("framework"):
            sc_rows.append(["í”„ë ˆì„ì›Œí¬", html_escape(str(scope["framework"]))])
        if scope.get("db_access"):
            db_list = scope["db_access"]
            if isinstance(db_list, list):
                sc_rows.append(["DB ì ‘ê·¼ ë°©ì‹", html_escape(", ".join(db_list))])
            else:
                sc_rows.append(["DB ì ‘ê·¼ ë°©ì‹", html_escape(str(db_list))])
        for key, label in [("controllers_scanned", "Controller"),
                           ("services_scanned", "Service"),
                           ("repositories_scanned", "Repository"),
                           ("mybatis_mappers_scanned", "MyBatis Mapper")]:
            if key in scope:
                sc_rows.append([label, str(scope[key])])
        if sc_rows:
            parts.append(_table(sc_headers, sc_rows))

    # summary
    summary = data.get("summary", {})
    if summary:
        parts.append("<h3>ìš”ì•½</h3>")
        total = summary.get("total_endpoints", 0)
        parts.append(f"<p>ì „ì²´ ì—”ë“œí¬ì¸íŠ¸: <strong>{total}</strong></p>")
        by_ctrl = summary.get("by_controller", {})
        if by_ctrl:
            c_headers = ["Controller", "ì—”ë“œí¬ì¸íŠ¸ ìˆ˜"]
            c_rows = []
            for ctrl_name, count in by_ctrl.items():
                # support both int and dict formats
                cnt = count if isinstance(count, int) else count.get("total", 0)
                c_rows.append([html_escape(ctrl_name), str(cnt)])
            parts.append(_table(c_headers, c_rows))
        by_method = summary.get("by_method", {})
        if by_method:
            m_headers = ["HTTP Method", "ê±´ìˆ˜"]
            m_rows = [[html_escape(str(k)), str(v)] for k, v in by_method.items()]
            parts.append(_table(m_headers, m_rows))
        auth_req = summary.get("auth_required_count")
        auth_not = summary.get("auth_not_required_count")
        if auth_req is not None:
            parts.append(f"<p>ì¸ì¦ í•„ìš”: {auth_req} / ì¸ì¦ ë¶ˆí•„ìš”: {auth_not}</p>")

    # endpoint list table
    findings = data.get("findings", [])
    if findings:
        parts.append("<h3>API ì—”ë“œí¬ì¸íŠ¸ ëª©ë¡</h3>")
        headers = ["Method", "API", "ì¸ì¦", "í•¸ë“¤ëŸ¬", "ì„¤ëª…"]
        rows = []
        for f in findings:
            auth_str = "í•„ìˆ˜" if f.get("auth_required") else "-"
            rows.append([
                f"<code>{html_escape(str(f.get('method', '')))}</code>",
                f"<code>{html_escape(str(f.get('api', '')))}</code>",
                html_escape(auth_str),
                f"<code>{html_escape(str(f.get('handler', '')))}</code>",
                html_escape(str(f.get("description", ""))),
            ])
        parts.append(_table(headers, rows))

    # detailed endpoint info - only for endpoints with parameters
    has_params = [f for f in findings if f.get("parameters")]
    if has_params:
        parts.append("<h2>ì—”ë“œí¬ì¸íŠ¸ ìƒì„¸ (íŒŒë¼ë¯¸í„° ë³´ìœ )</h2>")
        for f in has_params:
            api = html_escape(str(f.get("api", "")))
            method = html_escape(str(f.get("method", "")))
            handler = html_escape(str(f.get("handler", "")))
            desc = html_escape(str(f.get("description", "")))
            file_loc = html_escape(str(f.get("file", "")))

            parts.append(f"<h3><code>{method} {api}</code></h3>")
            parts.append(f"<p><strong>í•¸ë“¤ëŸ¬:</strong> <code>{handler}</code> "
                         f"(<code>{file_loc}</code>)</p>")
            parts.append(f"<p>{desc}</p>")

            resp_type = f.get("response_type", "")
            if resp_type:
                parts.append(f"<p><strong>ì‘ë‹µ:</strong> {html_escape(str(resp_type))}</p>")

            params = f.get("parameters", [])
            if params:
                p_headers = ["íŒŒë¼ë¯¸í„°", "íƒ€ì…", "ì¶œì²˜", "ê¸°ë³¸ê°’"]
                p_rows = []
                for p in params:
                    default = p.get("default")
                    default_str = html_escape(str(default)) if default is not None else "-"
                    p_rows.append([
                        f"<code>{html_escape(str(p.get('name', '')))}</code>",
                        f"<code>{html_escape(str(p.get('type', '')))}</code>",
                        html_escape(str(p.get("source", ""))),
                        default_str,
                    ])
                parts.append(_table(p_headers, p_rows))

    # legacy metadata support
    meta = data.get("metadata", {})
    if meta:
        parts.append("<h3>ë©”íƒ€ë°ì´í„°</h3>")
        if meta.get("framework"):
            parts.append(f"<p>í”„ë ˆì„ì›Œí¬: {html_escape(str(meta['framework']))}</p>")
        if meta.get("endpoint_count"):
            parts.append(f"<p>ì—”ë“œí¬ì¸íŠ¸ ìˆ˜: {meta['endpoint_count']}</p>")
        if meta.get("auth_mechanism"):
            parts.append(f"<p>ì¸ì¦ ë°©ì‹: {html_escape(str(meta['auth_mechanism']))}</p>")

    return "\n".join(parts)


def _json_to_xhtml_api_inventory(data):
    """Convert scan_api.py v3.0 output (endpoints key) to XHTML.

    Renders: summary stats, auth classification, endpoint table with
    auth detail, and per-endpoint parameter detail with DTO resolved fields.
    """
    source_dir = html_escape(str(data.get("source_dir", "")))
    total_ep = data.get("total_endpoints", 0)
    total_ctrl = data.get("total_controllers", 0)
    total_files = data.get("total_files_scanned", 0)

    parts = ["<h2>API ì¸ë²¤í† ë¦¬</h2>"]
    parts.append(f"<p><strong>ì†ŒìŠ¤:</strong> <code>{source_dir}</code></p>")

    # --- ìš”ì•½ í†µê³„ ---
    parts.append("<h3>ìŠ¤ìº” ìš”ì•½</h3>")
    sum_rows = [
        ["ìŠ¤ìº” íŒŒì¼", str(total_files)],
        ["ì»¨íŠ¸ë¡¤ëŸ¬", str(total_ctrl)],
        ["ì—”ë“œí¬ì¸íŠ¸", f"<strong>{total_ep}</strong>"],
    ]
    parts.append(_table(["í•­ëª©", "ê°’"], sum_rows))

    # HTTP ë©”ì„œë“œë³„
    method_stats = data.get("method_stats", {})
    if method_stats:
        parts.append("<h3>HTTP ë©”ì„œë“œë³„</h3>")
        m_rows = [[f"<code>{html_escape(k)}</code>", str(v)]
                   for k, v in sorted(method_stats.items())]
        parts.append(_table(["ë©”ì„œë“œ", "ê±´ìˆ˜"], m_rows))

    # ì¸ì¦ ë¶„ë¥˜ (ì´ì§„)
    auth_stats = data.get("auth_stats", {})
    if auth_stats:
        parts.append("<h3>ì¸ì¦ ë¶„ë¥˜</h3>")
        auth_req = auth_stats.get("auth_required", 0)
        auth_not = auth_stats.get("auth_not_required", 0)
        a_rows = [
            [_severity_badge("High").replace("High", "ì¸ì¦ í•„ìš”"), f"<strong>{auth_req}</strong>"],
            [_severity_badge("Info").replace("Info", "ì¸ì¦ ë¶ˆí•„ìš”"), f"<strong>{auth_not}</strong>"],
        ]
        parts.append(_table(["ë¶„ë¥˜", "ê±´ìˆ˜"], a_rows))

    # ë³´ì•ˆ ë“±ê¸‰ ìƒì„¸ (4-Level ë§¤íŠ¸ë¦­ìŠ¤)
    auth_detail_stats = data.get("auth_detail_stats", {})
    if auth_detail_stats:
        detail_labels = {
            "L1_ì™„ì „ì¸ì¦": "L1 ì™„ì „ ì¸ì¦ (required=true, permitted=true)",
            "L2_ê¸°ë³¸ì¸ì¦": "L2 ê¸°ë³¸ ì¸ì¦ (required=true)",
            "L3_ë¹„ì¸ì¦": "L3 ë¹„ì¸ì¦ (required=false)",
            "L4_ì¡°ê±´ë¶€ì¸ì¦": "L4 ì¡°ê±´ë¶€ ì¸ì¦ (required=false, permitted=true)",
            "preauthorize": "@PreAuthorize",
            "secured": "@Secured",
            "security_config": "Security Config",
            "no_auth_annotation": "ì¸ì¦ ì–´ë…¸í…Œì´ì…˜ ì—†ìŒ",
        }
        d_rows = []
        for key, count in sorted(auth_detail_stats.items(), key=lambda x: -x[1]):
            label = detail_labels.get(key, key)
            d_rows.append([html_escape(label), str(count)])
        if d_rows:
            parts.append("<p><em>ë³´ì•ˆ ë“±ê¸‰ ìƒì„¸:</em></p>")
            parts.append(_table(["ë“±ê¸‰", "ê±´ìˆ˜"], d_rows))

    # ì£¼ì„ ì²˜ë¦¬ëœ ì»¨íŠ¸ë¡¤ëŸ¬
    commented = data.get("commented_controllers", [])
    if commented:
        parts.append("<h3>ì£¼ì„ ì²˜ë¦¬ëœ ì»¨íŠ¸ë¡¤ëŸ¬ (ë¶„ì„ ì œì™¸)</h3>")
        c_rows = []
        for cc in commented:
            c_rows.append([
                f"<code>{html_escape(cc.get('class', ''))}</code>",
                str(cc.get("endpoint_count", 0)),
                html_escape(cc.get("reason", "")),
                f"<code>{html_escape(cc.get('file', ''))}</code>" if cc.get("file") else "-",
            ])
        parts.append(_table(["í´ë˜ìŠ¤", "ì—”ë“œí¬ì¸íŠ¸ ìˆ˜", "ì‚¬ìœ ", "íŒŒì¼"], c_rows))

    # ëª¨ë“ˆë³„ í†µê³„
    module_stats = data.get("module_stats", {})
    if module_stats:
        parts.append("<h3>ëª¨ë“ˆë³„</h3>")
        mod_rows = []
        for mod, stats in module_stats.items():
            mod_rows.append([
                html_escape(mod),
                str(stats.get("total", 0)),
                str(stats.get("auth_required", 0)),
                str(stats.get("no_auth", 0)),
            ])
        parts.append(_table(["ëª¨ë“ˆ", "ì „ì²´", "ì¸ì¦", "ë¹„ì¸ì¦"], mod_rows))

    # ë³´ì•ˆ ì„¤ì •
    sec_configs = data.get("security_configs", {})
    if sec_configs:
        parts.append("<h3>ë³´ì•ˆ ì„¤ì •</h3>")
        for mod, cfg in sec_configs.items():
            cfg_file = html_escape(str(cfg.get("config_file", "")))
            csrf = "ë¹„í™œì„±í™”" if cfg.get("csrf_disabled") else "í™œì„±í™”"
            cors = "ê°œë°©(*)" if cfg.get("cors_open") else "ì œí•œ"
            parts.append(f"<p><strong>{html_escape(mod)}:</strong> "
                         f"<code>{cfg_file}</code> "
                         f"(CSRF: {csrf}, CORS: {cors})</p>")

    # --- ì—”ë“œí¬ì¸íŠ¸ ëª©ë¡ í…Œì´ë¸” ---
    endpoints = data.get("endpoints", [])
    if endpoints:
        parts.append("<h2>ì—”ë“œí¬ì¸íŠ¸ ëª©ë¡</h2>")
        headers = ["#", "Method", "API", "ì¸ì¦", "ì¸ì¦ ìƒì„¸", "í•¸ë“¤ëŸ¬", "íŒŒì¼"]
        rows = []
        for idx, ep in enumerate(endpoints, 1):
            auth_required = ep.get("auth_required", False)
            auth_detail = ep.get("auth_detail", "")

            if auth_required:
                auth_badge = _severity_badge("High").replace("High", "í•„ìˆ˜")
            else:
                auth_badge = _severity_badge("Info").replace("Info", "ë¶ˆí•„ìš”")

            rows.append([
                str(idx),
                f"<code>{html_escape(str(ep.get('method', '')))}</code>",
                f"<code>{html_escape(str(ep.get('api', '')))}</code>",
                auth_badge,
                f"<code>{html_escape(auth_detail)}</code>" if auth_detail else "-",
                f"<code>{html_escape(str(ep.get('handler', '')))}</code>",
                f"<code>{html_escape(str(ep.get('file', '')))}</code>",
            ])
        parts.append(_table(headers, rows))

    # --- ì—”ë“œí¬ì¸íŠ¸ ìƒì„¸ (íŒŒë¼ë¯¸í„° ë³´ìœ ) ---
    has_params = [ep for ep in endpoints
                  if ep.get("parameters")
                  and any(p.get("type") not in ("request", "response", "exchange")
                          for p in ep["parameters"])]
    if has_params:
        parts.append("<h2>ì—”ë“œí¬ì¸íŠ¸ ìƒì„¸</h2>")
        for ep in has_params:
            api = html_escape(str(ep.get("api", "")))
            method = html_escape(str(ep.get("method", "")))
            handler = html_escape(str(ep.get("handler", "")))
            desc = html_escape(str(ep.get("description", "")))
            file_loc = html_escape(str(ep.get("file", "")))
            ret_type = html_escape(str(ep.get("return_type", "")))

            parts.append(f"<h3><code>{method} {api}</code></h3>")
            parts.append(f"<p><strong>í•¸ë“¤ëŸ¬:</strong> <code>{handler}</code> "
                         f"(<code>{file_loc}:{ep.get('line', '')}</code>)</p>")
            if desc:
                parts.append(f"<p>{desc}</p>")
            if ret_type:
                parts.append(f"<p><strong>ì‘ë‹µ:</strong> <code>{ret_type}</code></p>")

            # ì¸ì¦ ì •ë³´
            auth_detail = ep.get("auth_detail", "")
            if auth_detail:
                parts.append(f"<p><strong>ì¸ì¦:</strong> <code>{html_escape(auth_detail)}</code></p>")

            # ë¯¸ë“¤ì›¨ì–´
            mw = ep.get("middleware", [])
            if mw:
                mw_str = ", ".join(f"<code>{html_escape(m)}</code>" for m in mw)
                parts.append(f"<p><strong>ë¯¸ë“¤ì›¨ì–´:</strong> {mw_str}</p>")

            # íŒŒë¼ë¯¸í„° í…Œì´ë¸”
            params = [p for p in ep.get("parameters", [])
                      if p.get("type") not in ("request", "response", "exchange")]
            if params:
                p_headers = ["íŒŒë¼ë¯¸í„°", "ì¶œì²˜", "ë°ì´í„° íƒ€ì…", "í•„ìˆ˜", "ê¸°ë³¸ê°’"]
                p_rows = []
                for p in params:
                    req_str = "Y" if p.get("required") else "-"
                    default = p.get("default_value")
                    default_str = f"<code>{html_escape(str(default))}</code>" if default else "-"
                    dtype = html_escape(str(p.get("data_type", "")))
                    resolved = p.get("resolved_from", "")
                    if resolved:
                        dtype += f' <em>({html_escape(resolved)})</em>'

                    p_rows.append([
                        f"<code>{html_escape(str(p.get('name', '')))}</code>",
                        f"<code>{html_escape(str(p.get('type', '')))}</code>",
                        f"<code>{dtype}</code>",
                        req_str,
                        default_str,
                    ])
                parts.append(_table(p_headers, p_rows))

                # DTO resolved fields (ì„¸ë¶€ í•„ë“œ)
                for p in params:
                    resolved_fields = p.get("resolved_fields", [])
                    if resolved_fields:
                        resolved_from = html_escape(str(p.get("resolved_from", p.get("data_type", ""))))
                        parts.append(
                            f"<p><em><code>{html_escape(str(p.get('name', '')))}</code> "
                            f"íƒ€ì… <code>{resolved_from}</code> í•„ë“œ:</em></p>"
                        )
                        rf_headers = ["í•„ë“œ", "íƒ€ì…", "ì–´ë…¸í…Œì´ì…˜", "Nullable"]
                        rf_rows = []
                        for rf in resolved_fields:
                            annos = rf.get("annotations", [])
                            anno_str = " ".join(
                                f"<code>{html_escape(a)}</code>" for a in annos
                            ) if annos else "-"
                            inherited = rf.get("inherited", False)
                            name_str = html_escape(str(rf.get("name", "")))
                            if inherited:
                                inh_from = html_escape(str(rf.get("inherited_from", "")))
                                name_str += f" <em>(â† {inh_from})</em>"
                            rf_rows.append([
                                f"<code>{name_str}</code>",
                                f"<code>{html_escape(str(rf.get('data_type', '')))}</code>",
                                anno_str,
                                "Y" if rf.get("nullable") else "-",
                            ])
                        parts.append(_table(rf_headers, rf_rows))

    return "\n".join(parts)


def _json_to_xhtml_vuln(data):
    """Convert task_22/33/34 (vulnerability findings) JSON to XHTML."""
    task_id = data.get("task_id", "")
    target = data.get("target", "")
    parts = [f"<h2>ì·¨ì•½ì  ì§„ë‹¨ ê²°ê³¼ (Task {html_escape(str(task_id))})</h2>"]
    if target:
        parts.append(f"<p><strong>ëŒ€ìƒ:</strong> {html_escape(str(target))}</p>")

    # diagnosis criteria
    criteria = data.get("diagnosis_criteria", {})
    if criteria:
        vuln_pats = criteria.get("vulnerable_patterns", [])
        safe_pats = criteria.get("safe_patterns", [])
        if vuln_pats or safe_pats:
            parts.append("<h3>ì§„ë‹¨ ê¸°ì¤€</h3>")
        if vuln_pats:
            parts.append(f'<ac:structured-macro ac:name="warning">'
                         f'<ac:rich-text-body><p><strong>ì·¨ì•½ íŒ¨í„´:</strong></p><ul>')
            for pat in vuln_pats:
                parts.append(f"<li>{html_escape(str(pat))}</li>")
            parts.append("</ul></ac:rich-text-body></ac:structured-macro>")
        if safe_pats:
            parts.append(f'<ac:structured-macro ac:name="info">'
                         f'<ac:rich-text-body><p><strong>ì–‘í˜¸ íŒ¨í„´:</strong></p><ul>')
            for pat in safe_pats:
                parts.append(f"<li>{html_escape(str(pat))}</li>")
            parts.append("</ul></ac:rich-text-body></ac:structured-macro>")

    findings = data.get("findings", [])

    # severity summary
    sev_count = {}
    for f in findings:
        sev = f.get("severity", "Unknown")
        sev_count[sev] = sev_count.get(sev, 0) + 1
    if sev_count:
        parts.append("<h3>ì‹¬ê°ë„ë³„ ìš”ì•½</h3>")
        s_headers = ["ì‹¬ê°ë„", "ê±´ìˆ˜"]
        s_rows = []
        for sev in ["Critical", "High", "Medium", "Low", "Info"]:
            if sev in sev_count:
                s_rows.append([_severity_badge(sev), str(sev_count[sev])])
        parts.append(_table(s_headers, s_rows))

    # individual findings
    for f in findings:
        sev = f.get("severity", "")
        fid = html_escape(str(f.get("id", "")))
        title = html_escape(str(f.get("title", "")))
        parts.append(f"<h3>{fid} - {title} {_severity_badge(sev)}</h3>")
        parts.append(f"<p><strong>ì¹´í…Œê³ ë¦¬:</strong> {html_escape(str(f.get('category', '')))}</p>")
        parts.append(f"<p><strong>ì„¤ëª…:</strong> {html_escape(str(f.get('description', '')))}</p>")
        parts.append(f"<p><strong>ì˜í–¥ ë²”ìœ„:</strong> {html_escape(str(f.get('affected_endpoint', '')))}</p>")

        evidence = f.get("evidence", {})
        if evidence:
            efile = html_escape(str(evidence.get("file", "")))
            elines = html_escape(str(evidence.get("lines", "")))
            parts.append(f"<p><strong>ì¦ê±°:</strong> <code>{efile}:{elines}</code></p>")
            # call trace
            call_trace = evidence.get("call_trace", "")
            if call_trace:
                parts.append(f"<p><strong>í˜¸ì¶œ ì²´ì¸:</strong> <code>{html_escape(str(call_trace))}</code></p>")
            snippet = evidence.get("code_snippet", "")
            if snippet:
                efile_name = evidence.get("file", "")
                if efile_name.endswith(".java") or efile_name.endswith(".xml"):
                    lang = "java"
                elif efile_name.endswith(".kts"):
                    lang = "groovy"
                elif efile_name.endswith(".kt"):
                    lang = "java"  # Confluence Server/DC does not support "kotlin"
                elif efile_name.endswith(".py"):
                    lang = "python"
                elif efile_name.endswith(".js") or efile_name.endswith(".ts"):
                    lang = "javascript"
                else:
                    lang = "text"
                parts.append(_code_macro(snippet, lang))

        # attack example
        attack = f.get("attack_example", "")
        if attack:
            parts.append(f'<ac:structured-macro ac:name="warning">'
                         f'<ac:rich-text-body><p><strong>ê³µê²© ì˜ˆì‹œ:</strong> '
                         f'<code>{html_escape(str(attack))}</code></p>'
                         f'</ac:rich-text-body></ac:structured-macro>')

        cwe = f.get("cwe_id", "")
        owasp = f.get("owasp_category", "")
        if cwe or owasp:
            parts.append(f"<p><strong>CWE:</strong> {html_escape(str(cwe))} | "
                         f"<strong>OWASP:</strong> {html_escape(str(owasp))}</p>")

        rec = f.get("recommendation", "")
        if rec:
            parts.append(f'<ac:structured-macro ac:name="info">'
                         f'<ac:rich-text-body><p><strong>ê¶Œê³ ì‚¬í•­:</strong> '
                         f'{html_escape(rec)}</p></ac:rich-text-body>'
                         f'</ac:structured-macro>')

    # summary section
    summary = data.get("summary", {})
    if summary:
        parts.append("<h3>ì§„ë‹¨ ìš”ì•½</h3>")
        total = summary.get("total_findings", 0)
        parts.append(f"<p><strong>ì´ ë°œê²¬ ê±´ìˆ˜:</strong> {total}</p>")
        by_cat = summary.get("by_category", {})
        if by_cat:
            cat_headers = ["ì¹´í…Œê³ ë¦¬", "ê±´ìˆ˜"]
            cat_rows = [[html_escape(str(k)), str(v)] for k, v in by_cat.items()]
            parts.append(_table(cat_headers, cat_rows))
        by_exp = summary.get("by_exposure", {})
        if by_exp:
            exp_headers = ["ë…¸ì¶œ ìœ í˜•", "ê±´ìˆ˜"]
            exp_rows = [[html_escape(str(k)), str(v)] for k, v in by_exp.items()]
            parts.append(_table(exp_headers, exp_rows))
        risk = summary.get("risk_assessment", "")
        if risk:
            parts.append(f'<ac:structured-macro ac:name="panel">'
                         f'<ac:parameter ac:name="borderStyle">solid</ac:parameter>'
                         f'<ac:rich-text-body><p><strong>ìœ„í—˜ í‰ê°€:</strong> '
                         f'{html_escape(str(risk))}</p>'
                         f'</ac:rich-text-body></ac:structured-macro>')

    # safe patterns found
    safe = data.get("safe_patterns_found", {})
    if safe:
        items = safe.get("items", [])
        if items:
            parts.append("<h3>ì–‘í˜¸ íŒì • í•­ëª©</h3>")
            safe_headers = ["ìœ„ì¹˜", "íŒì • ì‚¬ìœ "]
            safe_rows = []
            for item in items:
                safe_rows.append([
                    f"<code>{html_escape(str(item.get('location', '')))}</code>",
                    html_escape(str(item.get("reason", ""))),
                ])
            parts.append(_table(safe_headers, safe_rows))

    # notes
    notes = data.get("notes")
    if notes:
        parts.append(f'<ac:structured-macro ac:name="note">'
                     f'<ac:rich-text-body><p>{html_escape(str(notes))}</p>'
                     f'</ac:rich-text-body></ac:structured-macro>')

    return "\n".join(parts)


# ============================================================
#  Enhanced Injection Report â€” Helper Functions
# ============================================================

_INTERNAL_TAG_RE = re.compile(
    r'\s*\[(?:non-DB method|non-DB|external|direct repo|from controller'
    r'|via [^\]]*|deprecated|JPA Repository[^\]]*)\]',
    re.IGNORECASE
)


def _clean_call(s: str) -> str:
    """Remove internal analysis tags from service/repo call strings."""
    return _INTERNAL_TAG_RE.sub('', s).strip()


def _simplify_category(ep: dict) -> str:
    """Map a diagnosis to a developer-friendly category name.

    ì·¨ì•½:
      [ì‹¤ì œ ìœ„í˜‘] SQL Injection       â€” í™•ì¸ëœ taint ê²½ë¡œ (HTTP íŒŒë¼ë¯¸í„° â†’ ${} ì‚½ì…)
      [ì ì¬ì  ìœ„í˜‘] ì·¨ì•½í•œ ì¿¼ë¦¬ êµ¬ì¡°   â€” ì·¨ì•½ êµ¬ì¡°ì´ë‚˜ taint ë¯¸í™•ì¸
    ì •ë³´:
      ì™¸ë¶€ ì˜ì¡´ì„± í˜¸ì¶œ                 â€” external_module (ì™¸ë¶€ ëª¨ë“ˆ ì˜ì¡´)
      XML ë¯¸ë°œê²¬ íŒ¨í„´ ì¶”ì •             â€” mybatis_safe + ì¶”ì • (XML ë¯¸ë°œê²¬)
      í˜¸ì¶œ ê²½ë¡œ ì¶”ì  ë¶ˆê°€              â€” ìë™ ì¶”ì  ì‹¤íŒ¨
      DB ì ‘ê·¼ ê²½ë¡œ ë¯¸í™•ì¸              â€” Service í˜¸ì¶œ í›„ Repository ë¯¸ì¶”ì 
    ì–‘í˜¸:
      JPA & ORM ë°©ì‹                  â€” JPA ë‚´ì¥ ë©”ì„œë“œ / @Query / ORM
      MyBatis #{} ë°”ì¸ë”©              â€” MyBatis XML/ì–´ë…¸í…Œì´ì…˜ #{} ë°”ì¸ë”©
      DB ë¯¸ì ‘ê·¼ ì—”ë“œí¬ì¸íŠ¸             â€” ë¹„DB Service, ë¹„DB í•¸ë“¤ëŸ¬, íŒŒë¼ë¯¸í„° ì—†ìŒ
      ì œì–´ íë¦„ìƒ ì•ˆì „                 â€” ê¸°íƒ€ ì•ˆì „ íŒ¨í„´ (bind, criteria ë“±)
    """
    result = ep.get("result", "ì •ë³´")
    dtype = ep.get("diagnosis_type", "")
    filter_type = ep.get("filter_type", "")

    if result == "ì·¨ì•½":
        if "[ì‹¤ì œ]" in dtype:
            return "[ì‹¤ì œ ìœ„í˜‘] SQL Injection"
        elif "[ì ì¬]" in dtype:
            return "[ì ì¬ì  ìœ„í˜‘] ì·¨ì•½í•œ ì¿¼ë¦¬ êµ¬ì¡°"
        # Fallback: legacy diagnosis_type ê°’ ëŒ€ì‘
        ft = filter_type.lower()
        if "tosql" in ft or "utils.tosql" in dtype.lower():
            return "[ì ì¬ì  ìœ„í˜‘] ì·¨ì•½í•œ ì¿¼ë¦¬ êµ¬ì¡°"
        return "[ì‹¤ì œ ìœ„í˜‘] SQL Injection"

    elif result == "ì •ë³´":
        if "ì™¸ë¶€ ì˜ì¡´ì„±" in dtype:
            return "ì™¸ë¶€ ì˜ì¡´ì„± í˜¸ì¶œ"
        elif "XML ë¯¸ë°œê²¬" in dtype:
            return "XML ë¯¸ë°œê²¬ íŒ¨í„´ ì¶”ì •"
        elif "ì¶”ì  ë¶ˆê°€" in dtype:
            return "í˜¸ì¶œ ê²½ë¡œ ì¶”ì  ë¶ˆê°€"
        elif "DB ì ‘ê·¼ ë¯¸í™•ì¸" in dtype:
            return "DB ì ‘ê·¼ ê²½ë¡œ ë¯¸í™•ì¸"
        return "ìˆ˜ë™ ê²€í†  í•„ìš”"

    else:  # ì–‘í˜¸
        if "JPA" in dtype or "@Query" in dtype or "ORM" in dtype:
            return "JPA & ORM ë°©ì‹"
        elif ("MyBatis" in dtype or "iBatis" in dtype
              or (filter_type.lower() == "mybatis" and "ì¶”ì •" not in dtype)):
            return "MyBatis #{} ë°”ì¸ë”©"
        elif ("ë¹„DB" in dtype or "ë¯¸ì ‘ê·¼" in dtype or "ë¯¸í˜¸ì¶œ" in dtype
              or "DB ì—†ìŒ" in dtype or "DB ì ‘ê·¼ ì—†ìŒ" in dtype
              or "ìœ í˜•4" in dtype or "íŒŒë¼ë¯¸í„°ì—†ìŒ" in dtype
              or "ì„¸ì…˜" in dtype or "deprecated" in dtype.lower()
              or "ë¹„í™œì„±" in dtype):
            return "DB ë¯¸ì ‘ê·¼ ì—”ë“œí¬ì¸íŠ¸"
        return "ì œì–´ íë¦„ìƒ ì•ˆì „"


def _confluence_code_block(content: str, language: str = "text") -> str:
    """Render a Confluence code block macro (XHTML storage format)."""
    safe = content.replace("]]>", "]] >")
    return (
        f'<ac:structured-macro ac:name="code">'
        f'<ac:parameter ac:name="language">{language}</ac:parameter>'
        f'<ac:parameter ac:name="theme">Confluence</ac:parameter>'
        f'<ac:plain-text-body><![CDATA[{safe}]]></ac:plain-text-body>'
        f'</ac:structured-macro>'
    )


def _confluence_expand(title: str, content: str) -> str:
    """Render a Confluence expand (accordion) macro."""
    return (
        f'<ac:structured-macro ac:name="expand">'
        f'<ac:parameter ac:name="title">{html_escape(title)}</ac:parameter>'
        f'<ac:rich-text-body>{content}</ac:rich-text-body>'
        f'</ac:structured-macro>'
    )


def _render_call_graph_text(ep: dict) -> str:
    """Build a text-format call graph for one endpoint."""
    handler = ep.get("handler", "")
    svc_calls = [_clean_call(s) for s in ep.get("service_calls", [])]
    repo_calls = [_clean_call(r) for r in ep.get("repository_calls", [])]
    db_ops = ep.get("db_operations", [])

    lines = []
    if handler:
        lines.append(f"[Controller] {handler}")
    for sc in svc_calls[:6]:
        if sc:
            lines.append(f"    â””â”€ [Service] {sc}")
    for rc in repo_calls[:6]:
        lines.append(f"        â””â”€ [Repository] {rc}")
    if db_ops and isinstance(db_ops, list):
        for op in db_ops[:2]:
            if isinstance(op, dict):
                detail = op.get("detail", "")
                # Trim verbose boilerplate
                detail = re.sub(r'\(ë©”ì„œë“œ í˜¸ì¶œ ì¶”ì¶œ[^)]*\)', '', detail).strip().rstrip(':')
                if detail:
                    lines.append(f"            â””â”€ [DB] {detail}")
    return "\n".join(lines) if lines else ""


def _render_ep_detail(ep: dict) -> str:
    """Render detailed evidence block for a representative endpoint."""
    parts = []
    method = ep.get("http_method", "")
    path = ep.get("request_mapping", "")
    handler = ep.get("handler", "")
    proc_file = ep.get("process_file", "")
    params = ep.get("parameters", "")
    diagnosis_detail = ep.get("diagnosis_detail", "")
    filter_detail = ep.get("filter_detail", "")
    db_ops = ep.get("db_operations", [])

    # Info table
    info_rows = [
        ["API", f"<code>{html_escape(method)} {html_escape(str(path))}</code>"],
        ["í•¸ë“¤ëŸ¬", f"<code>{html_escape(handler)}</code>"],
    ]
    if proc_file:
        info_rows.append(["ì†ŒìŠ¤ íŒŒì¼", f"<code>{html_escape(proc_file)}</code>"])
    if params:
        info_rows.append(["íŒŒë¼ë¯¸í„°", f"<code>{html_escape(str(params)[:300])}</code>"])
    if diagnosis_detail:
        clean_detail = re.sub(
            r'\(ë©”ì„œë“œ í˜¸ì¶œ ì¶”ì¶œ ì‹¤íŒ¨í•˜ì˜€ìœ¼ë‚˜ JPA ë‚´ì¥ ë©”ì„œë“œëŠ” ì•ˆì „\)', '', diagnosis_detail)
        info_rows.append(["íŒì • ê·¼ê±°", html_escape(clean_detail.strip())])
    parts.append(_table(["í•­ëª©", "ë‚´ìš©"], info_rows))

    # Call graph
    cg = _render_call_graph_text(ep)
    if cg:
        parts.append("<p><strong>í˜¸ì¶œ ê²½ë¡œ (Call Graph)</strong></p>")
        parts.append(_confluence_code_block(cg, "text"))

    # Code snippet from db_operations
    if db_ops and isinstance(db_ops, list):
        for op in db_ops:
            if isinstance(op, dict) and op.get("code_snippet"):
                lang = "java"  # Confluence Server/DC does not support "kotlin"
                parts.append("<p><strong>ì½”ë“œ ìŠ¤ë‹ˆí«</strong></p>")
                parts.append(_confluence_code_block(op["code_snippet"], lang))
                break

    # Vulnerable pattern detail
    if filter_detail and filter_detail not in ("N/A", ""):
        parts.append(
            f"<p><strong>ì·¨ì•½ íŒ¨í„´:</strong> "
            f"<code>{html_escape(filter_detail[:500])}</code></p>")

    return "".join(parts)


def _json_to_xhtml_enhanced_injection(data):
    """Convert scan_injection_enhanced.py output to developer-friendly XHTML.

    Structure:
      - ì§„ë‹¨ ìš”ì•½
      - ğŸš¨ ì·¨ì•½ (Vulnerable)  â€” category grouping, representative + expand
      - âš ï¸ ì •ë³´ (Manual Check) â€” category grouping, representative + expand
      - âœ… ì–‘í˜¸ (Safe)         â€” category grouping, representative + expand
      - ğŸ” ì „ì—­ ì·¨ì•½ì  (OS Command etc.) â€” code snippets with context
    """
    parts = ["<h2>ì¸ì ì…˜ ì·¨ì•½ì  ì§„ë‹¨ ê²°ê³¼</h2>"]

    # Metadata
    meta = data.get("scan_metadata", {})
    if meta:
        parts.append(
            f"<p>"
            f"<strong>ì†ŒìŠ¤:</strong> <code>{html_escape(str(meta.get('source_dir', '')))}</code>"
            f" &nbsp;|&nbsp; "
            f"<strong>ë¶„ì„ ë²„ì „:</strong> <code>{html_escape(str(meta.get('script_version', '')))}</code>"
            f"</p>"
        )

    # Summary table
    summary = data.get("summary", {})
    sqli = summary.get("sqli", {})
    os_cmd = summary.get("os_command", {})
    total = summary.get("total_endpoints", 0)
    vuln_n = sqli.get("ì·¨ì•½", 0)
    info_n = sqli.get("ì •ë³´", 0)
    safe_n = sqli.get("ì–‘í˜¸", 0)

    parts.append("<h3>ì§„ë‹¨ ìš”ì•½</h3>")
    sum_rows = [
        ["ì´ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸", f"<strong>{total}</strong>ê±´"],
        [
            f'{_severity_badge("High").replace("High", "ì·¨ì•½")} SQL Injection',
            f"<strong>{vuln_n}</strong>ê±´"
        ],
        [
            f'{_severity_badge("Medium").replace("Medium", "ì •ë³´")} ìˆ˜ë™ ê²€í†  í•„ìš”',
            f"<strong>{info_n}</strong>ê±´"
        ],
        [
            f'{_severity_badge("Info").replace("Info", "ì–‘í˜¸")} ì•ˆì „',
            f"<strong>{safe_n}</strong>ê±´"
        ],
        ["OS Command Injection", f"{os_cmd.get('total', 0)}ê±´ (í•˜ë‹¨ ì°¸ì¡°)"],
    ]
    parts.append(_table(["í•­ëª©", "ê²°ê³¼"], sum_rows))

    # Group endpoints by result
    diagnoses = data.get("endpoint_diagnoses", [])
    result_groups: dict = {}
    for ep in diagnoses:
        r = ep.get("result", "ì •ë³´")
        result_groups.setdefault(r, []).append(ep)

    def _render_result_section(result_key: str, icon: str, title_ko: str) -> str:
        eps = result_groups.get(result_key, [])
        if not eps:
            return ""

        sec = [f"<h3>{icon} {html_escape(title_ko)} â€” {len(eps)}ê±´</h3>"]

        # Sub-group by simplified category
        cat_groups: dict = {}
        for ep in eps:
            cat = _simplify_category(ep)
            cat_groups.setdefault(cat, []).append(ep)

        # Category summary table
        cat_rows = [
            [html_escape(cat), f"{len(ce)}ê±´"]
            for cat, ce in sorted(cat_groups.items(), key=lambda x: -len(x[1]))
        ]
        sec.append(_table(["ì›ì¸ ì¹´í…Œê³ ë¦¬", "ê±´ìˆ˜"], cat_rows))

        # Per-category detail
        for cat, cat_eps in sorted(cat_groups.items(), key=lambda x: -len(x[1])):
            representative = cat_eps[0]
            rest = cat_eps[1:]

            sec.append(f"<h4>{html_escape(cat)} ({len(cat_eps)}ê±´)</h4>")
            sec.append("<p><em>ëŒ€í‘œ ì‚¬ë¡€ ìƒì„¸:</em></p>")
            sec.append(_render_ep_detail(representative))

            if rest:
                rest_rows = []
                for idx, ep in enumerate(rest, 2):
                    svc = [_clean_call(s) for s in ep.get("service_calls", [])]
                    svc_str = " â†’ ".join(svc[:3]) if svc else "-"
                    if len(svc) > 3:
                        svc_str += f" +{len(svc) - 3}"
                    repo = [_clean_call(r) for r in ep.get("repository_calls", [])]
                    repo_str = ", ".join(repo[:2]) if repo else "-"
                    if len(repo) > 2:
                        repo_str += f" +{len(repo) - 2}"
                    rest_rows.append([
                        str(idx),
                        f"<code>{html_escape(str(ep.get('http_method', '')))}</code>",
                        f"<code>{html_escape(str(ep.get('request_mapping', '')))}</code>",
                        f"<code>{html_escape(str(ep.get('handler', '')))}</code>",
                        html_escape(svc_str),
                        html_escape(repo_str),
                    ])
                rest_table = _table(
                    ["#", "Method", "API", "í•¸ë“¤ëŸ¬", "ì„œë¹„ìŠ¤ í˜¸ì¶œ", "Repository"],
                    rest_rows
                )
                sec.append(_confluence_expand(
                    f"ë‚˜ë¨¸ì§€ {len(rest)}ê°œ API ëª©ë¡ í¼ì¹˜ê¸° â–¶",
                    rest_table
                ))

        return "".join(sec)

    parts.append(_render_result_section("ì·¨ì•½", "ğŸš¨", "ì·¨ì•½ (Vulnerable)"))
    parts.append(_render_result_section("ì •ë³´", "âš ï¸", "ì •ë³´ â€” ìˆ˜ë™ ê²€í†  í•„ìš” (Info)"))
    parts.append(_render_result_section("ì–‘í˜¸", "âœ…", "ì–‘í˜¸ (Safe)"))

    # --- Global Findings: OS Command, SSI ---
    global_findings = data.get("global_findings", {})
    if isinstance(global_findings, dict):
        for cat_key, cat_data in global_findings.items():
            if isinstance(cat_data, dict):
                findings = cat_data.get("findings", [])
                total_f = cat_data.get("total", 0)
            elif isinstance(cat_data, list):
                findings = cat_data
                total_f = len(findings)
            else:
                continue
            if not findings:
                continue

            cat_label = cat_key.replace("_", " ").title()
            parts.append(
                f"<h3>ğŸ” ì „ì—­ ì·¨ì•½ì  â€” {html_escape(cat_label)} ({total_f}ê±´)</h3>"
            )
            parts.append(
                "<p><em>ì•„ë˜ íŒ¨í„´ì€ ì „ì²´ ì†ŒìŠ¤ì½”ë“œ ìˆ˜ì¤€ì—ì„œ ê°ì§€ëœ í•­ëª©ì…ë‹ˆë‹¤. "
                "exec() ë™ë°˜ ì—¬ë¶€ ë° ì‚¬ìš©ì ì…ë ¥ ì†ŒìŠ¤ë¥¼ ìˆ˜ë™ìœ¼ë¡œ í™•ì¸í•˜ì„¸ìš”.</em></p>"
            )

            def _render_global_finding(f: dict, idx: int) -> str:
                fname = f.get("file", "")
                line = f.get("line", 0)
                pattern = f.get("pattern_name", f.get("pattern_id", ""))
                desc = f.get("description", "")
                snippet = f.get("code_snippet", "")
                ctx_before = f.get("context_before", [])
                ctx_after = f.get("context_after", [])
                safe_indicators = f.get("safe_indicators", [])

                fp = [f"<h5>{idx}. {html_escape(pattern)}</h5>"]
                d_rows = [
                    ["íŒŒì¼", f"<code>{html_escape(fname)}:{line}</code>"],
                    ["ì„¤ëª…", html_escape(desc)],
                ]
                if safe_indicators:
                    d_rows.append(["ì•ˆì „ ì§€í‘œ", html_escape(", ".join(str(s) for s in safe_indicators))])
                fp.append(_table(["í•­ëª©", "ë‚´ìš©"], d_rows))

                if snippet or ctx_before or ctx_after:
                    full_lines = [str(ln) for ln in (ctx_before or [])[-3:]]
                    if snippet:
                        full_lines.append(f">>> {snippet}   â† ê²€ì¶œ ë¼ì¸ {line}")
                    full_lines.extend(str(ln) for ln in (ctx_after or [])[:3])
                    lang = "java"  # Confluence Server/DC does not support "kotlin"
                    fp.append("<p><strong>ì½”ë“œ ìŠ¤ë‹ˆí«</strong></p>")
                    fp.append(_confluence_code_block("\n".join(full_lines), lang))
                return "".join(fp)

            # First finding shown directly
            parts.append(_render_global_finding(findings[0], 1))
            if len(findings) > 1:
                rest_content = "".join(
                    _render_global_finding(f, i)
                    for i, f in enumerate(findings[1:], 2)
                )
                parts.append(_confluence_expand(
                    f"ë‚˜ë¨¸ì§€ {len(findings) - 1}ê±´ ë” ë³´ê¸° â–¶",
                    rest_content
                ))

    return "\n".join(parts)


def _json_to_xhtml_enhanced_xss(data):
    """Convert scan_xss.py output (v1.1+) to developer-friendly XHTML.

    Structure:
      - ì§„ë‹¨ ìš”ì•½ (per-type summary table)
      - XSS ì „ì—­ í•„í„° í˜„í™©
      - âœ… ì–‘í˜¸ / ğŸš¨ ì·¨ì•½ / âš ï¸ ì •ë³´ endpoint grouping
      - ì •ë³´ í•­ëª© (í•„í„° ë¯¸ì„¤ì • ë“±)
    """
    parts = ["<h2>XSS ì·¨ì•½ì  ì§„ë‹¨ ê²°ê³¼</h2>"]

    meta = data.get("scan_metadata", {})
    if meta:
        parts.append(
            f"<p>"
            f"<strong>ì†ŒìŠ¤:</strong> <code>{html_escape(str(meta.get('source_dir', '')))}</code>"
            f" &nbsp;|&nbsp; "
            f"<strong>ë¶„ì„ ë²„ì „:</strong> <code>{html_escape(str(meta.get('script_version', '')))}</code>"
            f"</p>"
        )

    # --- ì§„ë‹¨ ìš”ì•½ ---
    summary = data.get("summary", {})
    total_ep = summary.get("total_endpoints", 0)
    xss_counts = summary.get("xss", {})
    per_type = summary.get("per_type", {})

    parts.append("<h3>ì§„ë‹¨ ìš”ì•½</h3>")
    sum_rows = [
        ["ì´ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸", f"<strong>{total_ep}</strong>ê±´"],
        [f'{_severity_badge("High").replace("High", "ì·¨ì•½")} XSS ì·¨ì•½',
         f"<strong>{xss_counts.get('ì·¨ì•½', 0)}</strong>ê±´"],
        [f'{_severity_badge("Medium").replace("Medium", "ì •ë³´")} ìˆ˜ë™ ê²€í†  í•„ìš”',
         f"<strong>{xss_counts.get('ì •ë³´', 0)}</strong>ê±´"],
        [f'{_severity_badge("Info").replace("Info", "ì–‘í˜¸")} ì•ˆì „',
         f"<strong>{xss_counts.get('ì–‘í˜¸', 0)}</strong>ê±´"],
    ]
    parts.append(_table(["í•­ëª©", "ê²°ê³¼"], sum_rows))

    # --- Per-type ë¶„ë¥˜ í…Œì´ë¸” ---
    if per_type:
        parts.append("<h3>XSS ìœ í˜•ë³„ ì§„ë‹¨ ê²°ê³¼</h3>")
        _type_labels = {
            "reflected_xss": "Reflected XSS",
            "view_xss": "View XSS (JSP/Thymeleaf)",
            "persistent_xss": "Persistent XSS",
            "redirect_xss": "Redirect XSS",
            "dom_xss": "DOM XSS",
        }
        pt_rows = []
        for key, label in _type_labels.items():
            val = per_type.get(key, {})
            if isinstance(val, dict):
                vuln = val.get("ì·¨ì•½", 0)
                safe = val.get("ì–‘í˜¸", 0)
                na = val.get("í•´ë‹¹ì—†ìŒ", 0)
                info = val.get("ì •ë³´", 0)
                if vuln > 0:
                    badge = _severity_badge("High").replace("High", "ì·¨ì•½")
                    detail = f"ì·¨ì•½ {vuln}ê±´"
                elif info > 0:
                    badge = _severity_badge("Medium").replace("Medium", "ì •ë³´")
                    detail = f"ì •ë³´ {info}ê±´"
                elif safe > 0:
                    badge = _severity_badge("Info").replace("Info", "ì–‘í˜¸")
                    detail = f"ì–‘í˜¸ {safe}ê±´"
                else:
                    badge = "<em>í•´ë‹¹ì—†ìŒ</em>"
                    detail = f"í•´ë‹¹ì—†ìŒ {na}ê±´"
                pt_rows.append([label, badge, detail])
            else:
                # dom_xss can be a string summary
                pt_rows.append([label, "<em>ì „ì—­ ìŠ¤ìº”</em>",
                                 html_escape(str(val)[:200])])
        parts.append(_table(["XSS ìœ í˜•", "ê²°ê³¼", "ìƒì„¸"], pt_rows))

    # --- ì „ì—­ XSS í•„í„° í˜„í™© ---
    global_filter = meta.get("global_xss_filter", {})
    if global_filter:
        has_filter = global_filter.get("has_filter", False)
        filter_type = html_escape(str(global_filter.get("filter_type", "ì—†ìŒ")))
        filter_detail = html_escape(str(global_filter.get("filter_detail", "")))
        filter_badge = (_severity_badge("Info").replace("Info", "ì ìš©ë¨")
                        if has_filter
                        else _severity_badge("Medium").replace("Medium", "ë¯¸ì„¤ì •"))
        parts.append("<h3>XSS ì „ì—­ í•„í„°</h3>")
        f_rows = [
            ["í•„í„° ìƒíƒœ", filter_badge],
            ["í•„í„° ìœ í˜•", filter_type],
        ]
        if filter_detail:
            f_rows.append(["ìƒì„¸", filter_detail])
        # ì„¸ë¶€ í•„í„° ëª©ë¡
        for fkey, flabel in [("has_lucy", "Lucy XSS Filter"),
                              ("has_antisamy", "AntiSamy"),
                              ("has_esapi", "ESAPI"),
                              ("has_ss_xss", "Spring Security XSS"),
                              ("has_jackson_xss", "Jackson XSS Deserializer")]:
            if global_filter.get(fkey):
                f_rows.append([flabel, "âœ“ ë°œê²¬"])
        parts.append(_table(["í•­ëª©", "ê°’"], f_rows))

    # --- Endpoint ëª©ë¡ (ê²°ê³¼ë³„ ê·¸ë£¹) ---
    diagnoses = data.get("endpoint_diagnoses", [])

    def _render_xss_group(result_key, icon, title_ko):
        eps = [ep for ep in diagnoses if ep.get("result") == result_key]
        if not eps:
            return ""
        sec = [f"<h3>{icon} {html_escape(title_ko)} â€” {len(eps)}ê±´</h3>"]
        ep_rows = []
        for ep in eps:
            reflected = html_escape(str(ep.get("reflected_xss", "N/A")))
            view = html_escape(str(ep.get("view_xss", "N/A")))
            persistent = html_escape(str(ep.get("persistent_xss", "N/A")))
            redirect = html_escape(str(ep.get("redirect_xss", "N/A")))
            dom = html_escape(str(ep.get("dom_xss", "N/A")))
            ep_rows.append([
                f"<code>{html_escape(str(ep.get('http_method', '')))}</code>",
                f"<code>{html_escape(str(ep.get('request_mapping', '')))}</code>",
                html_escape(str(ep.get("controller_type", ""))),
                reflected, view, persistent, redirect, dom,
            ])
        sec.append(_table(
            ["Method", "API", "Controller ìœ í˜•",
             "Reflected", "View", "Persistent", "Redirect", "DOM"],
            ep_rows))
        # ì·¨ì•½ endpoint ìƒì„¸
        if result_key == "ì·¨ì•½":
            for ep in eps:
                detail = html_escape(str(ep.get("diagnosis_detail", "")))
                evidence = ep.get("evidence", [])
                if detail or evidence:
                    api = html_escape(str(ep.get("request_mapping", "")))
                    method = html_escape(str(ep.get("http_method", "")))
                    sec.append(f"<h4><code>{method} {api}</code> ì·¨ì•½ ìƒì„¸</h4>")
                    if detail:
                        sec.append(f"<p>{detail}</p>")
                    for ev in evidence[:3]:
                        if isinstance(ev, dict):
                            efile = html_escape(str(ev.get("file", "")))
                            eline = html_escape(str(ev.get("line", "")))
                            snippet = ev.get("code_snippet", "")
                            if efile:
                                sec.append(f"<p><strong>ìœ„ì¹˜:</strong> "
                                           f"<code>{efile}:{eline}</code></p>")
                            if snippet:
                                sec.append(_confluence_code_block(snippet, "java"))
        return "".join(sec)

    parts.append(_render_xss_group("ì·¨ì•½", "ğŸš¨", "ì·¨ì•½ (Vulnerable)"))
    parts.append(_render_xss_group("ì •ë³´", "âš ï¸", "ì •ë³´ â€” ìˆ˜ë™ ê²€í†  í•„ìš” (Info)"))
    parts.append(_render_xss_group("ì–‘í˜¸", "âœ…", "ì–‘í˜¸ (Safe)"))

    # --- ì •ë³´ í•­ëª©: XSS ì „ì—­ í•„í„° ë¯¸ì„¤ì • ---
    if global_filter and not global_filter.get("has_filter"):
        parts.append("<h3>âš ï¸ ì •ë³´ í•­ëª© â€” XSS ì „ì—­ í•„í„° ë¯¸ì„¤ì •</h3>")
        parts.append(
            f'<ac:structured-macro ac:name="info">'
            f'<ac:rich-text-body>'
            f'<p><strong>í˜„í™©:</strong> Lucy XSS Filter, AntiSamy, ESAPI, '
            f'Jackson XSS Deserializer ë“± ì „ì—­ XSS í•„í„° ë¯¸ë°œê²¬</p>'
            f'<p><strong>í˜„ì¬ ìœ„í—˜ë„:</strong> <strong>ë‚®ìŒ</strong> â€” '
            f'REST API JSON ì‘ë‹µ êµ¬ì¡°ë¡œ ì„œë²„ ë ˆë²¨ XSS ë°œìƒ ê²½ë¡œ ì—†ìŒ</p>'
            f'<p><strong>í–¥í›„ ìœ„í—˜:</strong> HTML View ì¶”ê°€ ë˜ëŠ” ì™¸ë¶€ í¬í„¸ì´ '
            f'ì´ API ì‘ë‹µì„ HTMLì— ì§ì ‘ ë Œë”ë§í•˜ëŠ” ê²½ìš° ìœ„í—˜</p>'
            f'<p><strong>ê¶Œê³ :</strong> JSON Request Bodyìš© Jackson XSS Deserializer '
            f'ë˜ëŠ” Spring Security ê¸°ë°˜ í•„í„° ì ìš© ê²€í† </p>'
            f'</ac:rich-text-body></ac:structured-macro>'
        )
        parts.append(_confluence_code_block(
            "// ê¶Œê³ : Jackson ObjectMapperì— XSS Deserializer ì „ì—­ ë“±ë¡\n"
            "mapper.registerModule(new SimpleModule()\n"
            "    .addDeserializer(String.class, new XSSStringDeserializer()));",
            "java"
        ))

    # --- DOM XSS ì „ì—­ ìŠ¤ìº” ê²°ê³¼ ---
    dom_xss_scan = meta.get("dom_xss_scan", {})
    if dom_xss_scan and isinstance(dom_xss_scan, dict):
        dom_files = dom_xss_scan.get("total_files_scanned", 0)
        dom_findings = dom_xss_scan.get("findings", [])
        parts.append("<h3>DOM XSS ì „ì—­ ìŠ¤ìº”</h3>")
        dom_rows = [
            ["ìŠ¤ìº” íŒŒì¼ ìˆ˜ (JS/TS/Vue)", str(dom_files)],
            ["DOM XSS íŒ¨í„´ ë°œê²¬", str(len(dom_findings))],
        ]
        parts.append(_table(["í•­ëª©", "ê°’"], dom_rows))
        if dom_findings:
            for f in dom_findings[:5]:
                fname = html_escape(str(f.get("file", "")))
                line = f.get("line", 0)
                pattern = html_escape(str(f.get("pattern_name", "")))
                snippet = f.get("code_snippet", "")
                parts.append(f"<p><code>{fname}:{line}</code> â€” {pattern}</p>")
                if snippet:
                    parts.append(_confluence_code_block(snippet, "javascript"))

    return "\n".join(parts)


def _json_to_xhtml_final(data):
    """Convert final_report.json to XHTML."""
    parts = ["<h1>AI ë³´ì•ˆ ì§„ë‹¨ ìµœì¢… ë³´ê³ ì„œ</h1>"]

    # Executive Summary
    es = data.get("executive_summary", {})
    if es:
        parts.append("<h2>Executive Summary</h2>")
        parts.append(f'<ac:structured-macro ac:name="panel">'
                     f'<ac:parameter ac:name="borderStyle">solid</ac:parameter>'
                     f'<ac:rich-text-body>')
        parts.append(f"<p><strong>ì „ì²´ ì·¨ì•½ì :</strong> {es.get('total_vulnerabilities', 0)}</p>")
        parts.append(f"<p><strong>ìœ„í—˜ ì ìˆ˜:</strong> {es.get('risk_score', 0)} / 100</p>")
        parts.append(f"<p><strong>Critical:</strong> {es.get('critical_count', 0)} | "
                     f"<strong>High:</strong> {es.get('high_count', 0)}</p>")
        rec = es.get("recommendation", "")
        if rec:
            parts.append(f"<p><strong>ê¶Œê³ :</strong> {html_escape(rec)}</p>")
        parts.append("</ac:rich-text-body></ac:structured-macro>")

    # Summary - severity distribution
    summary = data.get("summary", {})
    if summary:
        parts.append("<h2>ì§„ë‹¨ ìš”ì•½</h2>")
        parts.append(f"<p>ì´ íƒœìŠ¤í¬: {summary.get('total_tasks', 0)} (ì™„ë£Œ: "
                     f"{summary.get('tasks_completed', 0)})</p>")
        parts.append(f"<p>ì´ ë°œê²¬ í•­ëª©: {summary.get('total_findings', 0)}</p>")
        parts.append(f"<p>ìœ„í—˜ ì ìˆ˜: {summary.get('risk_score', 0)} / 100</p>")

        dist = summary.get("severity_distribution", {})
        if dist:
            parts.append("<h3>ì‹¬ê°ë„ ë¶„í¬</h3>")
            d_headers = ["ì‹¬ê°ë„", "ê±´ìˆ˜"]
            d_rows = []
            for sev in ["Critical", "High", "Medium", "Low", "Info"]:
                count = dist.get(sev, 0)
                d_rows.append([_severity_badge(sev), str(count)])
            parts.append(_table(d_headers, d_rows))

    # All findings table
    findings = data.get("findings", [])
    if findings:
        parts.append("<h2>ì „ì²´ ì·¨ì•½ì  ëª©ë¡</h2>")
        f_headers = ["ID", "ì œëª©", "ì‹¬ê°ë„", "ì¹´í…Œê³ ë¦¬", "ì¶œì²˜"]
        f_rows = []
        for f in findings:
            f_rows.append([
                html_escape(str(f.get("id", ""))),
                html_escape(str(f.get("title", ""))),
                _severity_badge(f.get("severity", "")),
                html_escape(str(f.get("category", ""))),
                html_escape(str(f.get("source_task", ""))),
            ])
        parts.append(_table(f_headers, f_rows))

        # detailed findings
        parts.append("<h2>ìƒì„¸ ì·¨ì•½ì  ë‚´ì—­</h2>")
        for f in findings:
            sev = f.get("severity", "")
            fid = html_escape(str(f.get("id", "")))
            title = html_escape(str(f.get("title", "")))
            parts.append(f"<h3>{fid} - {title} {_severity_badge(sev)}</h3>")
            parts.append(f"<p><strong>ì¹´í…Œê³ ë¦¬:</strong> {html_escape(str(f.get('category', '')))}</p>")
            parts.append(f"<p><strong>ì„¤ëª…:</strong> {html_escape(str(f.get('description', '')))}</p>")
            parts.append(f"<p><strong>ì˜í–¥ ë²”ìœ„:</strong> {html_escape(str(f.get('affected_endpoint', '')))}</p>")

            evidence = f.get("evidence", {})
            if evidence:
                efile = html_escape(str(evidence.get("file", "")))
                elines = html_escape(str(evidence.get("lines", "")))
                parts.append(f"<p><strong>ì¦ê±°:</strong> {efile}:{elines}</p>")
                snippet = evidence.get("code_snippet", "")
                if snippet:
                    parts.append(_code_macro(snippet, "java"))

            cwe = f.get("cwe_id", "")
            owasp = f.get("owasp_category", "")
            if cwe or owasp:
                parts.append(f"<p><strong>CWE:</strong> {html_escape(str(cwe))} | "
                             f"<strong>OWASP:</strong> {html_escape(str(owasp))}</p>")

            rec = f.get("recommendation", "")
            if rec:
                parts.append(f'<ac:structured-macro ac:name="info">'
                             f'<ac:rich-text-body><p><strong>ê¶Œê³ ì‚¬í•­:</strong> '
                             f'{html_escape(rec)}</p></ac:rich-text-body>'
                             f'</ac:structured-macro>')

    # timestamp
    gen = data.get("generated_at", "")
    if gen:
        parts.append(f"<p><em>ìƒì„±ì¼ì‹œ: {html_escape(str(gen))}</em></p>")

    return "\n".join(parts)


def json_to_xhtml(data, json_type, source_path=""):
    """Route JSON data to the appropriate XHTML renderer based on type.

    json_type is one of: "finding", "final_report", "api_inventory"
    source_path helps disambiguate finding sub-types.
    """
    if json_type == "final_report":
        return _json_to_xhtml_final(data)

    # scan_api.py v3.0 format auto-detection (endpoints key)
    if json_type == "api_inventory" or "endpoints" in data:
        return _json_to_xhtml_api_inventory(data)

    # scan_xss.py format auto-detection (endpoint_diagnoses + per_type in summary)
    if "endpoint_diagnoses" in data and data.get("summary", {}).get("per_type"):
        return _json_to_xhtml_enhanced_xss(data)

    # scan_injection_enhanced.py format auto-detection (endpoint_diagnoses key)
    if "endpoint_diagnoses" in data:
        return _json_to_xhtml_enhanced_injection(data)

    # finding type - disambiguate by source file name or task_id
    basename = os.path.basename(source_path)
    task_id = str(data.get("task_id", ""))
    if basename.startswith("task_11") or "task_11" in basename or task_id == "1-1":
        return _json_to_xhtml_asset(data)
    if basename.startswith("task_21") or "task_21" in basename or task_id == "2-1":
        return _json_to_xhtml_api(data)
    # task_22, task_23, task_24, task_25 all use vulnerability format
    return _json_to_xhtml_vuln(data)

# ---------------------------------------------------------------------------
# Main Report (í†µí•© ë³´ê³ ì„œ) renderer
# ---------------------------------------------------------------------------

def _load_json_safe(rel_path: str, base_dir: str) -> dict:
    """Load a JSON file relative to base_dir. Returns {} on any error."""
    if not rel_path:
        return {}
    full = os.path.join(base_dir, rel_path)
    if not os.path.isfile(full):
        return {}
    try:
        with open(full, encoding="utf-8") as fh:
            return json.load(fh)
    except Exception:
        return {}


def _md_strip_detail_sections(md_content: str) -> str:
    """ì§„ë‹¨ë³´ê³ ì„œ.md ì—ì„œ ì„¸ë¶€ Task ì„¹ì…˜(ì¸ì ì…˜/XSS ìƒì„¸)ì„ ì œê±°í•˜ê³ 
    ê°œìš”Â·í•œê³„ ë¶€ë¶„ë§Œ ë°˜í™˜í•œë‹¤.

    ì œê±° ëŒ€ìƒ íŒ¨í„´ (## ë ˆë²¨ ì„¹ì…˜):
      ## 4.  Task 2-2 ì¸ì ì…˜ ...
      ## 5.  Task 2-3 XSS ...
      ## 6.  ì •ë³´ í•­ëª© ...

    ìœ ì§€ ëŒ€ìƒ:
      ## 1.  ì§„ë‹¨ ëŒ€ìƒ ê°œìš”
      ## 2.  ì¢…í•© ê²°ê³¼ ìš”ì•½  â† ì£¼ì„ ì²˜ë¦¬(JSON ìœ¼ë¡œ ëŒ€ì²´)
      ## 3.  API ì¸ë²¤í† ë¦¬   â† ì£¼ì„ ì²˜ë¦¬(JSON ìœ¼ë¡œ ëŒ€ì²´)
      ## 7.  ì „ì²´ ê²°ê³¼ ìš”ì•½ â† ì£¼ì„ ì²˜ë¦¬(JSON ìœ¼ë¡œ ëŒ€ì²´)
      ## 8.  ì§„ë‹¨ í•œê³„ ì‚¬í•­  â† ìœ ì§€
    """
    # ìœ ì§€í•  ìµœìƒìœ„ ì„¹ì…˜ ë²ˆí˜¸: 1, 8 (ê°œìš” + í•œê³„)
    # 2,3,7 ì€ JSON ê¸°ë°˜ ë™ì  ë Œë”ë§ìœ¼ë¡œ ëŒ€ì²´
    _KEEP_SECTION_NOS = {'1', '8'}
    _SKIP_SECTION_NOS = {'2', '3', '4', '5', '6', '7'}

    lines = md_content.splitlines()
    result_lines = []
    skip = False
    for line in lines:
        # ìµœìƒìœ„ ## ì„¹ì…˜ í—¤ë”© íƒì§€
        m = re.match(r'^##\s+(\d+)[\.\s]', line)
        if m:
            sec_no = m.group(1)
            if sec_no in _SKIP_SECTION_NOS:
                skip = True
                continue
            elif sec_no in _KEEP_SECTION_NOS:
                skip = False
        if not skip:
            result_lines.append(line)
    return '\n'.join(result_lines).strip()


def _build_main_summary_table(injection_data: dict, xss_data: dict) -> str:
    """JSON ë°ì´í„°ë¡œë¶€í„° í†µí•© ê²°ê³¼ ìš”ì•½ í‘œë¥¼ ìƒì„±í•œë‹¤.
    ì´ í•¨ìˆ˜ê°€ ë‹¨ì¼ ë°ì´í„° ì†ŒìŠ¤ì´ë¯€ë¡œ ì„¸ë¶€ ë³´ê³ ì„œì™€ ìˆ˜ì¹˜ê°€ í•­ìƒ ì¼ì¹˜í•œë‹¤."""
    rows = []

    # SQL Injection
    if injection_data:
        sqli = injection_data.get("summary", {}).get("sqli", {})
        vuln_n = sqli.get("ì·¨ì•½", 0)
        info_n = sqli.get("ì •ë³´", 0)
        result_str = "<strong>ì „ì²´ ì–‘í˜¸</strong>" if vuln_n == 0 and info_n == 0 \
            else f"<strong style='color:red'>ì·¨ì•½ {vuln_n}ê±´</strong>"
        rows.append(["SQL Injection", result_str,
                     f"{vuln_n}ê±´", f"{info_n}ê±´"])
        os_cmd = injection_data.get("summary", {}).get("os_command", {})
        os_total = os_cmd.get("total", 0)
        rows.append(["OS Command Injection",
                     "ì˜¤íƒ ê²€í†  í•„ìš”" if os_total else "í•´ë‹¹ì—†ìŒ",
                     "0ê±´", "0ê±´"])
        rows.append(["SSI Injection", "í•´ë‹¹ì—†ìŒ", "0ê±´", "0ê±´"])
    else:
        rows.append(["SQL Injection", "â€”", "â€”", "â€”"])
        rows.append(["OS Command Injection", "â€”", "â€”", "â€”"])
        rows.append(["SSI Injection", "â€”", "â€”", "â€”"])

    # XSS
    if xss_data:
        xss_sum = xss_data.get("summary", {}).get("xss", {})
        xss_vuln = xss_sum.get("ì·¨ì•½", 0)
        xss_info = xss_sum.get("ì •ë³´", 0)
        xss_result = "<strong>ì „ì²´ ì–‘í˜¸</strong>" \
            if xss_vuln == 0 and xss_info == 0 \
            else f"<strong style='color:red'>ì·¨ì•½ {xss_vuln}ê±´</strong>"
        rows.append(["XSS (ì „ì²´)", xss_result,
                     f"{xss_vuln}ê±´", f"{xss_info}ê±´"])
        per_type = xss_data.get("summary", {}).get("per_type", {})
        _xss_labels = [
            ("reflected_xss", "Reflected XSS"),
            ("view_xss",      "View XSS"),
            ("persistent_xss","Persistent XSS"),
            ("redirect_xss",  "Redirect XSS"),
            ("dom_xss",       "DOM XSS"),
        ]
        for key, label in _xss_labels:
            td = per_type.get(key, {})
            # per_type ê°’ì´ string ì¸ ê²½ìš°(dom_xss ì „ì—­ ìŠ¤ìº” ìš”ì•½ ë¬¸ìì—´)ëŠ” í•´ë‹¹ì—†ìŒ ì²˜ë¦¬
            if not isinstance(td, dict):
                rows.append([f"&nbsp;&nbsp;â€” {label}", "í•´ë‹¹ì—†ìŒ (ì „ì—­ ìŠ¤ìº”)",
                             "0ê±´", "0ê±´"])
                continue
            tv = td.get("ì·¨ì•½", 0)
            ti_n = td.get("ì •ë³´", 0)
            ts = td.get("ì–‘í˜¸", 0)
            na = td.get("í•´ë‹¹ì—†ìŒ", 0)
            if na and not tv and not ti_n and not ts:
                sub_result = "í•´ë‹¹ì—†ìŒ"
            elif tv == 0:
                sub_result = f"ì–‘í˜¸ {ts}ê±´"
            else:
                sub_result = f"ì·¨ì•½ {tv}ê±´"
            rows.append([f"&nbsp;&nbsp;â€” {label}", sub_result,
                         f"{tv}ê±´", f"{ti_n}ê±´"])
    else:
        rows.append(["XSS (ì „ì²´)", "â€”", "â€”", "â€”"])

    return _table(["ì§„ë‹¨ í•­ëª©", "ê²°ê³¼", "ì·¨ì•½ ê±´ìˆ˜", "ì •ë³´ ê±´ìˆ˜"], rows)


def _build_main_api_inventory(api_data: dict) -> str:
    """API ì¸ë²¤í† ë¦¬ JSON ì—ì„œ ì—”ë“œí¬ì¸íŠ¸ ëª©ë¡ í‘œë¥¼ ìƒì„±í•œë‹¤."""
    endpoints = api_data.get("endpoints", [])
    if not endpoints:
        return "<p>API ì¸ë²¤í† ë¦¬ ë°ì´í„° ì—†ìŒ</p>"
    rows = []
    for ep in endpoints:
        # scan_api.py v3 í¬ë§·: method/api  vs  ì´ì „ í¬ë§·: http_method/request_mapping
        method = ep.get("method", ep.get("http_method", ""))
        path = ep.get("api", ep.get("request_mapping", ""))
        handler = ep.get("handler", "")
        ctrl = handler.split(".")[0] if "." in handler else handler
        params = ep.get("parameters", [])
        if params:
            pnames = [p.get("name", str(p)) if isinstance(p, dict) else str(p)
                      for p in params[:6]]
            param_str = ", ".join(pnames)
            if len(params) > 6:
                param_str += f" â€¦ +{len(params)-6}ê°œ"
        else:
            param_str = "â€”"
        rows.append([
            f"<code>{html_escape(method)}</code>",
            f"<code>{html_escape(path)}</code>",
            html_escape(ctrl),
            html_escape(param_str[:120]),
        ])
    return _table(["Method", "Endpoint", "Controller", "Parameters"], rows)


def _json_to_xhtml_main_report(md_content: str, task_sources: dict,
                                base_dir: str) -> str:
    """í†µí•© ë³´ê³ ì„œ ë Œë”ëŸ¬ (type=main_report).

    ì—­í• :
      - ì§„ë‹¨ ëŒ€ìƒ ê°œìš” (md íŒŒì¼ì˜ ì„¹ì…˜ 1)
      - ì¢…í•© ê²°ê³¼ ìš”ì•½  (JSON ë°ì´í„° ê¸°ë°˜ â€” ì„¸ë¶€ ë³´ê³ ì„œì™€ ë™ì¼ ì†ŒìŠ¤)
      - API ì¸ë²¤í† ë¦¬   (API JSON ê¸°ë°˜)
      - ì§„ë‹¨ í•œê³„      (md íŒŒì¼ì˜ ì„¹ì…˜ 8)
      â€» ì¸ì ì…˜/XSS ì„¸ë¶€ ë‚´ìš©ì€ í¬í•¨í•˜ì§€ ì•ŠìŒ (ê° Task ë³´ê³ ì„œ í˜ì´ì§€ ì°¸ì¡°)
    """
    api_data       = _load_json_safe(task_sources.get("api", ""), base_dir)
    injection_data = _load_json_safe(task_sources.get("injection", ""), base_dir)
    xss_data       = _load_json_safe(task_sources.get("xss", ""), base_dir)

    parts = []

    # 1. ê°œìš”Â·í•œê³„ ì„¹ì…˜ (md ì—ì„œ ì¶”ì¶œ)
    overview_md = _md_strip_detail_sections(md_content)
    if overview_md:
        parts.append(md_to_xhtml(overview_md))

    # 2. ì¢…í•© ê²°ê³¼ ìš”ì•½ (JSON ê¸°ë°˜ â€” ë‹¨ì¼ ì†ŒìŠ¤)
    parts.append("<h2>ì¢…í•© ì§„ë‹¨ ê²°ê³¼ ìš”ì•½</h2>")
    parts.append("<p><em>ì•„ë˜ ìˆ˜ì¹˜ëŠ” ê° Task ì„¸ë¶€ ë³´ê³ ì„œ ë°ì´í„°ì™€ ë™ì¼í•œ ì†ŒìŠ¤ì—ì„œ ê³„ì‚°ë©ë‹ˆë‹¤.</em></p>")
    parts.append(_build_main_summary_table(injection_data, xss_data))

    # 3. API ì¸ë²¤í† ë¦¬
    if api_data:
        total_ep = len(api_data.get("endpoints", []))
        parts.append(f"<h2>API ì¸ë²¤í† ë¦¬ â€” ì´ {total_ep}ê°œ ì—”ë“œí¬ì¸íŠ¸</h2>")
        parts.append(_build_main_api_inventory(api_data))

    # 4. Task ë³´ê³ ì„œ ë§í¬ ì•ˆë‚´
    parts.append(
        "<h2>ì„¸ë¶€ ì§„ë‹¨ ê²°ê³¼</h2>"
        "<p>ì¸ì ì…˜Â·XSS ë“± ê° í•­ëª©ë³„ ìƒì„¸ ë‚´ìš©(ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜, Call Graph, "
        "ì½”ë“œ ì¦ì )ì€ í•˜ìœ„ Task ë³´ê³ ì„œ í˜ì´ì§€ë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.</p>"
        '<ac:structured-macro ac:name="children">'
        '<ac:parameter ac:name="sort">title</ac:parameter>'
        '</ac:structured-macro>'
    )

    return "\n".join(parts)


# ---------------------------------------------------------------------------
# Content resolver
# ---------------------------------------------------------------------------

def resolve_content(entry, base_dir):
    """Read source file and convert to XHTML based on entry type.

    Returns (xhtml_string, error_string_or_None).
    """
    source = entry["source"]
    full_path = os.path.join(base_dir, source)

    if not os.path.isfile(full_path):
        return None, f"File not found: {full_path}"

    try:
        with open(full_path, encoding="utf-8") as fh:
            raw = fh.read()
    except OSError as exc:
        return None, f"Cannot read {full_path}: {exc}"

    entry_type = entry.get("type", "doc")

    # main_report: í†µí•© ë³´ê³ ì„œ (ê°œìš”+ìš”ì•½ë§Œ, ì„¸ë¶€ ë‚´ìš©ì€ Task í˜ì´ì§€ì—)
    if entry_type == "main_report":
        task_sources = entry.get("task_sources", {})
        xhtml = _json_to_xhtml_main_report(raw, task_sources, base_dir)
        return xhtml, None

    if entry_type == "doc":
        xhtml = md_to_xhtml(raw)
        return xhtml, None

    # JSON types: finding, final_report
    try:
        data = json.loads(raw)
    except json.JSONDecodeError as exc:
        return None, f"Invalid JSON in {full_path}: {exc}"

    xhtml = json_to_xhtml(data, entry_type, source)
    return xhtml, None

# ---------------------------------------------------------------------------
# Main
# ---------------------------------------------------------------------------

def _publish_entry(cfg, entry, full_title, parent_id, base_dir, dry_run):
    """Publish a single entry. Returns True on success, False on error."""
    source = entry["source"]
    entry_type = entry.get("type", "doc")

    print(f"\n  [{entry_type.upper():12s}] {source}")
    print(f"  {'':12s}   -> \"{full_title}\"")
    print(f"  {'':12s}   parent: {parent_id}")

    xhtml, err = resolve_content(entry, base_dir)
    if err:
        print(f"  {'':12s}   !! {err}")
        return False

    content_len = len(xhtml) if xhtml else 0
    print(f"  {'':12s}   content: {content_len} chars XHTML")

    if dry_run:
        print(f"  {'':12s}   (dry-run: skipped)")
        return True

    try:
        page_id, action = publish_page(cfg, full_title, xhtml, parent_id)
        print(f"  {'':12s}   {action} -> page id: {page_id}")
        return True
    except SystemExit:
        return False


def _publish_group_parent(cfg, group, full_title, parent_id, base_dir, dry_run):
    """Create or update a group parent page. Returns page id.

    If the group dict contains a ``source`` key the file content is used as
    the page body.  Otherwise a placeholder with a children macro is generated.
    """
    source = group.get("source")
    if source:
        entry_stub = {"source": source, "type": group.get("type", "doc")}
        body, err = resolve_content(entry_stub, base_dir)
        if err:
            body = None
        if body:
            # append children macro so sub-pages are listed
            body += ('\n<hr/>'
                     '<ac:structured-macro ac:name="children">'
                     '<ac:parameter ac:name="sort">title</ac:parameter>'
                     '</ac:structured-macro>')
    else:
        body = None

    if not body:
        body = (f"<p>ì´ í˜ì´ì§€ëŠ” <strong>{html_escape(full_title)}</strong>ì˜ "
                f"í•˜ìœ„ ë¬¸ì„œë¥¼ ëª¨ì•„ë†“ì€ ìƒìœ„ í˜ì´ì§€ì…ë‹ˆë‹¤.</p>"
                f'<ac:structured-macro ac:name="children">'
                f'<ac:parameter ac:name="sort">title</ac:parameter>'
                f'</ac:structured-macro>')

    src_label = source or "(generated)"
    print(f"\n  [{'GROUP':12s}] {src_label}")
    print(f"  {'':12s}   -> \"{full_title}\"")
    print(f"  {'':12s}   parent: {parent_id}")
    print(f"  {'':12s}   content: {len(body)} chars XHTML")

    if dry_run:
        print(f"  {'':12s}   (dry-run: skipped)")
        return None

    try:
        page_id, action = publish_page(cfg, full_title, body, parent_id)
        print(f"  {'':12s}   {action} -> page id: {page_id}")
        return page_id
    except SystemExit:
        return None


def main():
    parser = argparse.ArgumentParser(
        description="Publish docs and findings to Confluence Server/DC.",
    )
    parser.add_argument(
        "--dry-run", action="store_true",
        help="Show what would be published without making API calls.",
    )
    parser.add_argument(
        "--map", default=None,
        help="Path to page map JSON (default: tools/confluence_page_map.json).",
    )
    parser.add_argument(
        "--base-dir", default=None,
        help="Base directory for resolving source paths (default: repo root).",
    )
    parser.add_argument(
        "--filter", default=None,
        help="Only publish entries matching this source path.",
    )
    args = parser.parse_args()

    # determine base directory
    script_dir = os.path.dirname(os.path.abspath(__file__))
    repo_root = os.path.abspath(os.path.join(script_dir, "..", ".."))
    base_dir = args.base_dir or repo_root

    # load .env
    load_env(os.path.join(base_dir, ".env"))

    # load page map
    map_path = args.map or os.path.join(base_dir, "tools", "confluence_page_map.json")
    if not os.path.isfile(map_path):
        print(f"[ERROR] Page map not found: {map_path}", file=sys.stderr)
        sys.exit(1)

    with open(map_path, encoding="utf-8") as fh:
        page_map = json.load(fh)

    prefix = page_map.get("prefix", "")
    root_page = page_map.get("root_page")
    entries = page_map.get("entries", [])
    groups = page_map.get("groups", [])

    # apply filter
    publish_root = True
    def _filter_groups(grps, filt):
        """Recursively filter groups by source path."""
        filtered = []
        for g in grps:
            gc = dict(g)
            gc["entries"] = [e for e in gc.get("entries", [])
                             if e["source"] == filt]
            gc["groups"] = _filter_groups(gc.get("groups", []), filt)
            if gc["entries"] or gc["groups"] or gc.get("source") == filt:
                filtered.append(gc)
        return filtered

    if args.filter:
        publish_root = (root_page and root_page.get("source") == args.filter)
        entries = [e for e in entries if e["source"] == args.filter]
        groups = _filter_groups(groups, args.filter)
        if not entries and not groups and not publish_root:
            print(f"[WARN] No entries match filter: {args.filter}", file=sys.stderr)
            sys.exit(0)
    else:
        publish_root = root_page is not None

    def _count_group_entries(grps):
        """Recursively count all publishable entries in groups."""
        n = 0
        for g in grps:
            n += len(g.get("entries", []))
            n += _count_group_entries(g.get("groups", []))
        return n

    total = len(entries) + _count_group_entries(groups)
    if publish_root:
        total += 1

    if not args.dry_run:
        cfg = get_config()
    else:
        cfg = None

    print(f"{'[DRY-RUN] ' if args.dry_run else ''}Publishing {total} entries "
          f"+ {len(groups)} group(s) (prefix: \"{prefix}\")")
    print("-" * 60)

    success = 0
    errors = 0
    root_parent = cfg["parent_id"] if cfg else "ROOT"

    # --- root page (update the parent page itself) ---
    if publish_root and root_page:
        print(f"\n{'='*40}")
        print(f"  Root page")
        print(f"{'='*40}")
        root_entry = {"source": root_page["source"],
                      "type": root_page.get("type", "doc")}
        xhtml, err = resolve_content(root_entry, base_dir)

        src = root_page["source"]
        print(f"\n  [{'ROOT':12s}] {src}")
        print(f"  {'':12s}   -> page id: {root_parent}")

        if err:
            print(f"  {'':12s}   !! {err}")
            errors += 1
        elif args.dry_run:
            print(f"  {'':12s}   content: {len(xhtml)} chars XHTML")
            print(f"  {'':12s}   (dry-run: skipped)")
            success += 1
        else:
            # append children macro so sub-pages are listed
            xhtml += ('\n<hr/>'
                      '<ac:structured-macro ac:name="children">'
                      '<ac:parameter ac:name="sort">title</ac:parameter>'
                      '</ac:structured-macro>')
            try:
                # directly update the root parent page by its known id
                params = urllib.parse.urlencode({"expand": "version"})
                page_info = confluence_api(
                    cfg, "GET",
                    f"/rest/api/content/{root_parent}?{params}")
                ver = page_info["version"]["number"]
                title = page_info["title"]
                update_page(cfg, root_parent, title, xhtml, ver)
                print(f"  {'':12s}   content: {len(xhtml)} chars XHTML")
                print(f"  {'':12s}   updated -> page id: {root_parent}")
                success += 1
            except SystemExit:
                errors += 1

    # --- flat entries (docs) under root parent ---
    if entries:
        print(f"\n{'='*40}")
        print(f"  Top-level entries ({len(entries)})")
        print(f"{'='*40}")
    for entry in entries:
        raw_title = entry["title"]
        full_title = f"{prefix} {raw_title}" if prefix else raw_title
        ok = _publish_entry(cfg, entry, full_title, root_parent,
                            base_dir, args.dry_run)
        success += ok
        errors += (not ok)

    # --- groups (findings under group parent, supports nesting) ---
    def _publish_groups(grps, parent_id, depth=0):
        nonlocal success, errors
        for group in grps:
            group_raw_title = group["title"]
            group_full_title = f"{prefix} {group_raw_title}" if prefix else group_raw_title
            group_entries = group.get("entries", [])
            sub_groups = group.get("groups", [])
            child_count = len(group_entries) + _count_group_entries(sub_groups)

            indent = "  " * depth
            print(f"\n{indent}{'='*40}")
            print(f"{indent}  Group: \"{group_full_title}\" ({child_count} entries)")
            print(f"{indent}{'='*40}")

            group_parent_id = _publish_group_parent(
                cfg, group, group_full_title, parent_id, base_dir, args.dry_run)

            if not args.dry_run and group_parent_id is None:
                print(f"{indent}  !! Failed to create group parent, skipping children")
                errors += len(group_entries) + _count_group_entries(sub_groups)
                continue

            child_parent = group_parent_id if group_parent_id else "GROUP"

            for entry in group_entries:
                raw_title = entry["title"]
                full_title = f"{prefix} {raw_title}" if prefix else raw_title
                ok = _publish_entry(cfg, entry, full_title, child_parent,
                                    base_dir, args.dry_run)
                success += ok
                errors += (not ok)

            if sub_groups:
                _publish_groups(sub_groups, child_parent, depth + 1)

    _publish_groups(groups, root_parent)

    print("\n" + "=" * 60)
    print(f"Done. {success} succeeded, {errors} failed out of {total} entries.")

    if errors > 0:
        sys.exit(1)


if __name__ == "__main__":
    main()
